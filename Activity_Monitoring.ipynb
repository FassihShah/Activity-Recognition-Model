{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "pdDqcs8naek8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load filtered training data\n",
        "tr_Acc = np.load(\"train_Accelerometer_OpenDoor_RubHands.npy\")\n",
        "tr_Grav = np.load(\"train_Gravity_OpenDoor_RubHands.npy\")\n",
        "tr_labels = np.load(\"train_labels_OpenDoor_RubHands.npy\")\n",
        "\n",
        "# Load filtered testing data\n",
        "ts_Acc = np.load(\"test_Accelerometer_OpenDoor_RubHands.npy\")\n",
        "ts_Grav = np.load(\"test_Gravity_OpenDoor_RubHands.npy\")\n",
        "ts_labels = np.load(\"test_labels_OpenDoor_RubHands.npy\")\n",
        "\n",
        " # converting labels to binary\n",
        "tr_labels = np.where(tr_labels == 20, 0, 1)\n",
        "ts_labels = np.where(ts_labels == 20, 0, 1)\n"
      ],
      "metadata": {
        "id": "Snkv0ynnpfJW"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes of the loaded data\n",
        "print(\"Training Accelerometer shape:\", tr_Acc.shape)\n",
        "print(\"Training Gravity shape:\", tr_Grav.shape)\n",
        "print(\"Training Labels shape:\", tr_labels.shape)\n",
        "\n",
        "print(\"Testing Accelerometer shape:\", ts_Acc.shape)\n",
        "print(\"Testing Gravity shape:\", ts_Grav.shape)\n",
        "print(\"Testing Labels shape:\", ts_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc2hZT8CrR2a",
        "outputId": "6133d35d-e17f-4bcf-eef6-68fd5a8dbe01"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accelerometer shape: (87, 800, 3)\n",
            "Training Gravity shape: (87, 800, 3)\n",
            "Training Labels shape: (87,)\n",
            "Testing Accelerometer shape: (90, 800, 3)\n",
            "Testing Gravity shape: (90, 800, 3)\n",
            "Testing Labels shape: (90,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "RGWGasN1cuun"
      },
      "outputs": [],
      "source": [
        "# Set number of training and testing examples\n",
        "train_num_examples = 87\n",
        "test_num_examples = 90\n",
        "\n",
        "num_sensors = 2\n",
        "num_features_per_axis = 8\n",
        "num_axes = 3\n",
        "\n",
        "train_features = np.zeros((train_num_examples, num_sensors * num_features_per_axis, num_axes))\n",
        "test_features = np.zeros((test_num_examples, num_sensors * num_features_per_axis, num_axes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYtMK-jPhhL0",
        "outputId": "a6c0c132-9559-4398-a15f-490df4e13948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (87, 16, 3)\n",
            "Test features shape: (90, 16, 3)\n"
          ]
        }
      ],
      "source": [
        "# Generation of features for training dataset\n",
        "# Accelerometer features\n",
        "train_features[:, 0, :] = np.mean(tr_Acc, axis=1)\n",
        "train_features[:, 1, :] = np.max(tr_Acc, axis=1)\n",
        "train_features[:, 2, :] = np.min(tr_Acc, axis=1)\n",
        "train_features[:, 3, :] = np.std(tr_Acc, axis=1)\n",
        "train_features[:, 4, :] = np.sum(np.diff(np.sign(tr_Acc), axis=1) != 0, axis=1)\n",
        "train_features[:, 5, :] = np.percentile(tr_Acc, 20, axis=1)\n",
        "train_features[:, 6, :] = np.percentile(tr_Acc, 50, axis=1)\n",
        "train_features[:, 7, :] = np.percentile(tr_Acc, 80, axis=1)\n",
        "\n",
        "# Gravity features\n",
        "train_features[:, 8, :] = np.mean(tr_Grav, axis=1)\n",
        "train_features[:, 9, :] = np.max(tr_Grav, axis=1)\n",
        "train_features[:, 10, :] = np.min(tr_Grav, axis=1)\n",
        "train_features[:, 11, :] = np.std(tr_Grav, axis=1)\n",
        "train_features[:, 12, :] = np.sum(np.diff(np.sign(tr_Grav), axis=1) != 0, axis=1)\n",
        "train_features[:, 13, :] = np.percentile(tr_Grav, 20, axis=1)\n",
        "train_features[:, 14, :] = np.percentile(tr_Grav, 50, axis=1)\n",
        "train_features[:, 15, :] = np.percentile(tr_Grav, 80, axis=1)\n",
        "\n",
        "# Generation of features for testing dataset\n",
        "# Accelerometer features\n",
        "test_features[:, 0, :] = np.mean(ts_Acc, axis=1)\n",
        "test_features[:, 1, :] = np.max(ts_Acc, axis=1)\n",
        "test_features[:, 2, :] = np.min(ts_Acc, axis=1)\n",
        "test_features[:, 3, :] = np.std(ts_Acc, axis=1)\n",
        "test_features[:, 4, :] = np.sum(np.diff(np.sign(ts_Acc), axis=1) != 0, axis=1)\n",
        "test_features[:, 5, :] = np.percentile(ts_Acc, 20, axis=1)\n",
        "test_features[:, 6, :] = np.percentile(ts_Acc, 50, axis=1)\n",
        "test_features[:, 7, :] = np.percentile(ts_Acc, 80, axis=1)\n",
        "\n",
        "# Gravity features\n",
        "test_features[:, 8, :] = np.mean(ts_Grav, axis=1)\n",
        "test_features[:, 9, :] = np.max(ts_Grav, axis=1)\n",
        "test_features[:, 10, :] = np.min(ts_Grav, axis=1)\n",
        "test_features[:, 11, :] = np.std(ts_Grav, axis=1)\n",
        "test_features[:, 12, :] = np.sum(np.diff(np.sign(ts_Grav), axis=1) != 0, axis=1)\n",
        "test_features[:, 13, :] = np.percentile(ts_Grav, 20, axis=1)\n",
        "test_features[:, 14, :] = np.percentile(ts_Grav, 50, axis=1)\n",
        "test_features[:, 15, :] = np.percentile(ts_Grav, 80, axis=1)\n",
        "\n",
        "print(\"Train features shape:\", train_features.shape)\n",
        "print(\"Test features shape:\", test_features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjRl0wF5nulQ",
        "outputId": "67061c1a-cb92-4143-c3ec-843ef2c799a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features reshaped shape: (87, 48)\n",
            "Test features reshaped shape: (90, 48)\n"
          ]
        }
      ],
      "source": [
        "train_features_reshaped = np.reshape(train_features, (train_features.shape[0], train_features.shape[1] * train_features.shape[2]))\n",
        "test_features_reshaped = np.reshape(test_features, (test_features.shape[0], test_features.shape[1] * test_features.shape[2]))\n",
        "\n",
        "print(\"Train features reshaped shape:\", train_features_reshaped.shape)\n",
        "print(\"Test features reshaped shape:\", test_features_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_tensor = torch.from_numpy(train_features_reshaped).float()\n",
        "test_features_tensor = torch.from_numpy(test_features_reshaped).float()\n",
        "train_labels_tensor = torch.from_numpy(tr_labels).float().view(-1, 1)\n",
        "test_labels_tensor = torch.from_numpy(ts_labels).float().view(-1, 1)\n",
        "\n",
        "batch_size = 50\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "\n",
        "#OPEN_DOOR == 0\n",
        "#RUB_HANDS == 1\n",
        "\n",
        "#Create DataLoader for batch processing\n",
        "train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
        "test_dataset = TensorDataset(test_features_tensor, test_labels_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "mPXC_nu0cj_R"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo22UH9YulZr",
        "outputId": "42abfb36-2bc0-4adf-893b-4ea87933000e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/100], Loss: 0.0173\n",
            "Test Accuracy: 94.44%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      1.00      0.95        48\n",
            "         1.0       1.00      0.88      0.94        42\n",
            "\n",
            "    accuracy                           0.94        90\n",
            "   macro avg       0.95      0.94      0.94        90\n",
            "weighted avg       0.95      0.94      0.94        90\n",
            "\n",
            "Confusion Matrix:\n",
            "[[48  0]\n",
            " [ 5 37]]\n"
          ]
        }
      ],
      "source": [
        "# Neural Network Model\n",
        "\n",
        "class BinaryClassificationModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(BinaryClassificationModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "input_size = train_features_reshaped.shape[1]  # 48 features\n",
        "model = BinaryClassificationModel(input_size)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "predict_list = []\n",
        "test_list = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs > 0.5).float()  # Convert sigmoid output to binary (0 or 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        predict_list.append(predicted)\n",
        "        test_list.append(labels)\n",
        "\n",
        "predict_list = torch.cat(predict_list)\n",
        "test_list = torch.cat(test_list)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_list,predict_list))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_list,predict_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRL9pp8c2ERN",
        "outputId": "4ea51335-db8f-4cbc-c1c1-f8205382e8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      1.00      0.96        48\n",
            "         1.0       1.00      0.90      0.95        42\n",
            "\n",
            "    accuracy                           0.96        90\n",
            "   macro avg       0.96      0.95      0.95        90\n",
            "weighted avg       0.96      0.96      0.96        90\n",
            "\n",
            "Confusion Matrix:\n",
            "[[48  0]\n",
            " [ 4 38]]\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression Model\n",
        "\n",
        "log_reg_classifier = LogisticRegression(solver='liblinear')\n",
        "log_reg_classifier.fit(train_features_reshaped, tr_labels)\n",
        "\n",
        "#Predict on the test data\n",
        "estimatedLabels = log_reg_classifier.predict(test_features_reshaped)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels_tensor, estimatedLabels))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels_tensor, estimatedLabels))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}